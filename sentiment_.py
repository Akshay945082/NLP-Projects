# -*- coding: utf-8 -*-
"""Sentiment .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/123TBK1uNWfn-SFhb6rqLEyXTLoshP581

### Importing required libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import nltk
from nltk.stem.porter import PorterStemmer
nltk.download('stopwords')
from nltk.corpus import stopwords
STOPWORDS = set(stopwords.words('english'))
from nltk.tokenize import word_tokenize
from sklearn.model_selection import train_test_split
from sentence_transformers import SentenceTransformer
from sklearn.preprocessing import MinMaxScaler
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, accuracy_score
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.model_selection import GridSearchCV
from sklearn.model_selection import StratifiedKFold
!pip install xgboost
import xgboost as xgb
from xgboost import XGBClassifier
from sklearn.model_selection import RandomizedSearchCV
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier

#Load the data
data = pd.read_excel(r"/content/CNG_sentiment.xlsx")
print(f"Dataset shape : {data.shape}")

data.head()

#Column names
print(f"Feature names : {data.columns.values}")

"""There is one record with no 'verified_reviews' (null value)"""

#We will drop the null record
data.dropna(inplace=True)

print(f"Dataset shape after dropping null values : {data.shape}")

# Strip any leading or trailing spaces from column names
data.columns = data.columns.str.strip()
data_cleaned = data.dropna()
print(f"Dataset shape after removing NaN rows: {data_cleaned.shape}")
print(data_cleaned.isnull().sum())

data_cleaned.head()

data_cleaned.dtypes

len(data_cleaned)

"""Let's plot the above values in a pie chart

"""

feedback_counts = data_cleaned['Feedback'].value_counts()
plt.figure(figsize=(10, 7))
feedback_counts.plot.pie(autopct='%1.1f%%', colors=['lightgreen', 'lightyellow', 'red'],
                          startangle=90, wedgeprops={'edgecolor': 'black'})
plt.gca().set_facecolor('white')
plt.title('Sentiment Distribution')
plt.legend(feedback_counts.index, fontsize='8')
plt.show()

# separating the data and labels
X = data_cleaned['Comments'].values
Y1 = data_cleaned['Label'].values

#print(X)

nltk.download('punkt')
stemmer = PorterStemmer()
corpus = data_cleaned['Comments'].astype(str).tolist()
corpus_tokenized = [word_tokenize(comment.lower()) for comment in corpus]
corpus_stemmed = [' '.join([stemmer.stem(word) for word in comment]) for comment in corpus_tokenized]
print(corpus_stemmed[:5])

X= corpus_stemmed

#X

tokenized_corpus = [word_tokenize(sentence.lower()) for sentence in X]

#tokenized_corpus

import nltk
nltk.download('vader_lexicon')

from nltk.sentiment.vader import SentimentIntensityAnalyzer
sid=SentimentIntensityAnalyzer()

a= "Can I ride this bike 350km in a day?"
sid.polarity_scores(a)

sid.polarity_scores(data_cleaned['Comments'][0])

data_cleaned['scores']=data_cleaned['Comments'].apply(lambda Comments:sid.polarity_scores(Comments))

data_cleaned.head()

data_cleaned['compound']=data_cleaned['scores'].apply(lambda score_dict:score_dict['compound'])

data_cleaned.head(10)

data_cleaned['comp_score'] = data_cleaned['compound'].apply(lambda c: 'positive' if c > 0 else ('negative' if c < 0 else 'neutral'))
data_cleaned.head(7)

# Extract y_actual and y_predict
y_actual = data_cleaned['Feedback']
y_predict = data_cleaned['comp_score']
print("y_actual:")
print(y_actual)
print("y_predict:")
print(y_predict)

y_predict = data_cleaned['comp_score']

# Define the mapping
mapping = {
    'positive': 1,
    'neutral': 0,
    'negative': -1
}
y_predict_numeric = y_predict.map(mapping)
print("Converted y_predict:")
print(y_predict_numeric)

data_cleaned['Feedback'] = data_cleaned['Feedback'].str.lower()
data_cleaned['comp_score'] = data_cleaned['comp_score'].str.lower()
y_actual = data_cleaned['Feedback']
y_predict = data_cleaned['comp_score']
cm = confusion_matrix(y_actual, y_predict, labels=['positive', 'neutral', 'negative'])
print("Confusion Matrix:")
print(cm)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Positive', 'Neutral', 'Negative'], yticklabels=['Positive', 'Neutral', 'Negative'])
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.title('Confusion Matrix')
plt.show()
print("\nClassification Report:")
print(classification_report(y_actual, y_predict, target_names=['Positive', 'Neutral', 'Negative']))

# 2nd part

# Calculate accuracy
accuracy = accuracy_score(y_actual, y_predict)

# Print classification report for metrics
print("\nClassification Report:")
print(classification_report(y_actual, y_predict, target_names=['Positive', 'Neutral', 'Negative']))
print(f"\nAccuracy: {accuracy:.2f}")

accuracy*100

# Print classification report for  metrics
print("\nClassification Report:")
print(classification_report(y_actual, y_predict, target_names=['Positive', 'Neutral', 'Negative']))
print('my bike is good')

#new DataFrame df1 with only the 'Stemmed_Comments' column
df1 = data_cleaned[['Comments']].copy()
df1.head(7)

df1.isnull().sum()

pip install sentence_transformers

model = SentenceTransformer('all-MiniLM-L6-v2')
sentences = df1['Comments'].tolist()
sentence_embeddings = model.encode(sentences)
print(sentence_embeddings)

X= sentence_embeddings
Y = data_cleaned['Label']

X

data_cleaned['y1'] = data_cleaned['Label'].apply(lambda x: 0 if x == -1 else (1 if x == 0 else 2))
print(data_cleaned[['Label', 'y1']].head(8))

# Convert 'y1' column to a NumPy array
y1_array = data_cleaned['y1'].to_numpy()
print(y1_array)

Y1= y1_array

Y1

x_train, x_test, y_train, y_test = train_test_split(X, Y1, test_size=0.2, random_state=42)

print("Size of x_train:", (x_train.shape))
print("Size of y_train:", (y_train.shape))
print("Size of x_test:", (x_test.shape))
print("Size of y_test:", (y_test.shape))

y_test

x_train

y_train

import warnings
warnings.filterwarnings('ignore')
from sklearn.linear_model import LogisticRegression

logreg = LogisticRegression()
logreg.fit(x_train, y_train)
logreg_pred = logreg.predict(x_test)
logreg_acc = accuracy_score(logreg_pred, y_test)
print("Test accuracy: {:.2f}%".format(logreg_acc*100))

print(confusion_matrix(y_test, logreg_pred))
print("\n")
print(classification_report(y_test, logreg_pred))

style.use('classic')
cm = confusion_matrix(y_test, logreg_pred, labels=logreg.classes_)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=logreg.classes_)
disp.plot()
plt.show()

# XGBoost
xgboost_model = xgb.XGBClassifier()
xgboost_model.fit(x_train, y_train)
xgboost_pred = xgboost_model.predict(x_test)
xgboost_acc = accuracy_score(xgboost_pred, y_test)
print("XGBoost Test accuracy: {:.2f}%".format(xgboost_acc * 100))

# Set up the parameter grid to tune
param_grid = {
    'n_estimators': [100],
    'learning_rate': [0.1],
    'max_depth': [3],
    'subsample': [0.8],
    'colsample_bytree': [0.8],
}
grid_search = GridSearchCV(estimator=xgboost_model, param_grid=param_grid,
                           cv=3, scoring='accuracy', verbose=1, n_jobs=-1)
grid_search.fit(x_train, y_train)
best_xgboost_model = grid_search.best_estimator_
xgboost_pred = best_xgboost_model.predict(x_test)
xgboost_acc = accuracy_score(xgboost_pred, y_test)
print("Best Parameters:", grid_search.best_params_)
print("XGBoost Test accuracy after tuning: {:.2f}%".format(xgboost_acc * 100))

xgboost_model = XGBClassifier()
xgboost_model.fit(x_train, y_train)
xgboost_pred = xgboost_model.predict(x_test)
xgboost_acc = accuracy_score(xgboost_pred, y_test)
print("XGBoost Test accuracy: {:.2f}%".format(xgboost_acc * 100))

print(confusion_matrix(y_test, xgboost_pred))
print("\n")
print(classification_report(y_test, xgboost_pred))

# XGBoost classifier
xgboost_model = xgb.XGBClassifier()
random_search = RandomizedSearchCV(estimator=xgboost_model,
                                   param_distributions=param_grid,
                                   n_iter=10,
                                   scoring='accuracy',
                                   cv=3,
                                   verbose=1,
                                   n_jobs=-1,
                                   random_state=42)
random_search.fit(x_train, y_train)
best_xgboost_model = random_search.best_estimator_
xgboost_pred = best_xgboost_model.predict(x_test)
xgboost_acc = accuracy_score(y_test, xgboost_pred)
print("Best Parameters:", random_search.best_params_)
print("XGBoost Test accuracy after tuning: {:.2f}%".format(xgboost_acc * 100))
print(confusion_matrix(y_test, xgboost_pred))
print("\n")
print(classification_report(y_test, xgboost_pred))

print(confusion_matrix(y_test, xgboost_pred))
print("\n")
print(classification_report(y_test, xgboost_pred))

pip install tensorflow

# Initialize the ANN model
ann_model = Sequential()
ann_model.add(Dense(units=64, activation='relu', input_dim=x_train.shape[1]))
ann_model.add(Dense(units=32, activation='relu'))
ann_model.add(Dense(units=3, activation='softmax'))
ann_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
ann_model.fit(x_train, y_train, epochs=30, batch_size=16, verbose=1)
y_pred_prob = ann_model.predict(x_test)
y_pred = y_pred_prob.argmax(axis=1)
ann_acc = accuracy_score(y_test, y_pred)
print("ANN Test accuracy: {:.2f}%".format(ann_acc * 100))

print(confusion_matrix(y_test, y_pred))
print("\n")
print(classification_report(y_test, y_pred))

ann_model = Sequential()
ann_model.add(Dense(units=256, activation='relu', input_dim=x_train.shape[1]))
ann_model.add(Dense(units=128, activation='relu'))
ann_model.add(Dense(units=64, activation='relu'))
ann_model.add(Dense(units=3, activation='softmax'))
optimizer = Adam(learning_rate=0.0005)
ann_model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
ann_model.fit(x_train, y_train, epochs=30, batch_size=64, verbose=1)
y_pred_prob = ann_model.predict(x_test)
y_pred = y_pred_prob.argmax(axis=1)
ann_acc = accuracy_score(y_test, y_pred)
print("Tuned ANN Test accuracy: {:.2f}%".format(ann_acc * 100))

SVCmodel = LinearSVC()
SVCmodel.fit(x_train, y_train)

svc_pred = SVCmodel.predict(x_test)
svc_acc = accuracy_score(svc_pred, y_test)
print("test accuracy: {:.2f}%".format(svc_acc*100))

print(confusion_matrix(y_test, svc_pred))
print("\n")
print(classification_report(y_test, svc_pred))

#SVM
svm_model = SVC()
svm_model.fit(x_train, y_train)
svm_pred = svm_model.predict(x_test)
svm_accuracy = accuracy_score(y_test, svm_pred)
print(f"SVM Accuracy: {svm_accuracy:.2f}")

# Knn
knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(x_train, y_train)
knn_pred = knn_model.predict(x_test)
knn_accuracy = accuracy_score(y_test, knn_pred)
print(f"KNN Accuracy: {knn_accuracy:.2f}")

# Get the classification reports for both models
svc_report = classification_report(y_test, svc_pred, output_dict=True)
xgboost_report = classification_report(y_test, xgboost_pred, output_dict=True)
svc_metrics = [svc_report['1']['precision'] * 100, svc_report['1']['recall'] * 100, svc_report['1']['f1-score'] * 100]
xgboost_metrics = [xgboost_report['1']['precision'] * 100, xgboost_report['1']['recall'] * 100, xgboost_report['1']['f1-score'] * 100]
metrics_labels = ['Precision', 'Recall', 'F1-Score']
bar_width = 0.30
index = np.arange(len(metrics_labels))
fig, ax = plt.subplots(figsize=(10,6))
bar_svc = ax.bar(index, svc_metrics, bar_width, label='SVC', color='red')
bar_xgboost = ax.bar(index + bar_width, xgboost_metrics, bar_width, label='XGBoost', color='green')
ax.set_xlabel('Metrics')
ax.set_ylabel('Percentage (%)')
ax.set_title('Comparison of SVC and XGBoost Metrics')
ax.set_xticks(index + bar_width / 2)
ax.set_xticklabels(metrics_labels)
ax.legend(fontsize=10)
for i, v in enumerate(svc_metrics):
    ax.text(i - 0.1, v + 1, f'{v:.1f}%', color='black', fontsize=10)
for i, v in enumerate(xgboost_metrics):
    ax.text(i + bar_width - 0.1, v + 1, f'{v:.1f}%', color='black', fontsize=10)
ax.yaxis.grid(True)
ax.xaxis.grid(False)
plt.xlim([-0.5, len(metrics_labels)])
plt.tight_layout()
plt.show()

